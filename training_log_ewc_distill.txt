[Step=50, Epoch=0.45] {'loss': 0.4287, 'grad_norm': 1.269873023033142, 'learning_rate': 2.5200000000000003e-05, 'epoch': 0.45454545454545453}
[Step=100, Epoch=0.91] {'loss': 0.1664, 'grad_norm': 5.8725128173828125, 'learning_rate': 2.4e-05, 'epoch': 0.9090909090909091}
[Step=150, Epoch=1.36] {'loss': 0.1392, 'grad_norm': 0.7410735487937927, 'learning_rate': 2.2800000000000002e-05, 'epoch': 1.3636363636363638}
[Step=200, Epoch=1.82] {'loss': 0.0925, 'grad_norm': 0.22772245109081268, 'learning_rate': 2.1600000000000003e-05, 'epoch': 1.8181818181818183}
[Step=250, Epoch=2.27] {'loss': 0.0387, 'grad_norm': 0.12893930077552795, 'learning_rate': 2.04e-05, 'epoch': 2.2727272727272725}
[Step=300, Epoch=2.73] {'loss': 0.0871, 'grad_norm': 0.17443792521953583, 'learning_rate': 1.9200000000000003e-05, 'epoch': 2.7272727272727275}
[Step=350, Epoch=3.18] {'loss': 0.0695, 'grad_norm': 0.1314891129732132, 'learning_rate': 1.8e-05, 'epoch': 3.1818181818181817}
[Step=400, Epoch=3.64] {'loss': 0.0456, 'grad_norm': 0.10518145561218262, 'learning_rate': 1.6800000000000002e-05, 'epoch': 3.6363636363636362}
[Step=450, Epoch=4.09] {'loss': 0.0644, 'grad_norm': 0.10236234962940216, 'learning_rate': 1.5600000000000003e-05, 'epoch': 4.090909090909091}
[Step=500, Epoch=4.55] {'loss': 0.0428, 'grad_norm': 0.06326079368591309, 'learning_rate': 1.44e-05, 'epoch': 4.545454545454545}
[Step=550, Epoch=5.00] {'loss': 0.0545, 'grad_norm': 0.20727550983428955, 'learning_rate': 1.32e-05, 'epoch': 5.0}
[Step=600, Epoch=5.45] {'loss': 0.0352, 'grad_norm': 0.07395687699317932, 'learning_rate': 1.2e-05, 'epoch': 5.454545454545454}
[Step=650, Epoch=5.91] {'loss': 0.0346, 'grad_norm': 0.14892365038394928, 'learning_rate': 1.0800000000000002e-05, 'epoch': 5.909090909090909}
[Step=700, Epoch=6.36] {'loss': 0.0347, 'grad_norm': 0.04890924692153931, 'learning_rate': 9.600000000000001e-06, 'epoch': 6.363636363636363}
[Step=750, Epoch=6.82] {'loss': 0.0181, 'grad_norm': 0.10299184918403625, 'learning_rate': 8.400000000000001e-06, 'epoch': 6.818181818181818}
[Step=800, Epoch=7.27] {'loss': 0.0144, 'grad_norm': 0.0523989200592041, 'learning_rate': 7.2e-06, 'epoch': 7.2727272727272725}
[Step=850, Epoch=7.73] {'loss': 0.0418, 'grad_norm': 0.05591138079762459, 'learning_rate': 6e-06, 'epoch': 7.7272727272727275}
[Step=900, Epoch=8.18] {'loss': 0.0195, 'grad_norm': 6.5841383934021, 'learning_rate': 4.800000000000001e-06, 'epoch': 8.181818181818182}
[Step=950, Epoch=8.64] {'loss': 0.0241, 'grad_norm': 0.7863826751708984, 'learning_rate': 3.6e-06, 'epoch': 8.636363636363637}
[Step=1000, Epoch=9.09] {'loss': 0.018, 'grad_norm': 0.048317816108465195, 'learning_rate': 2.4000000000000003e-06, 'epoch': 9.090909090909092}
[Step=1050, Epoch=9.55] {'loss': 0.0204, 'grad_norm': 0.18385568261146545, 'learning_rate': 1.2000000000000002e-06, 'epoch': 9.545454545454545}
[Step=1100, Epoch=10.00] {'loss': 0.0284, 'grad_norm': 0.0805249810218811, 'learning_rate': 0.0, 'epoch': 10.0}
[Step=1100, Epoch=10.00] {'train_runtime': 548.4146, 'train_samples_per_second': 15.919, 'train_steps_per_second': 2.006, 'total_flos': 2297578217472000.0, 'train_loss': 0.06902011221105402, 'epoch': 10.0}
[Step=50, Epoch=0.45] {'loss': 0.3615, 'grad_norm': 0.2599504590034485, 'learning_rate': 7.977272727272728e-05, 'epoch': 0.45454545454545453}
[Step=100, Epoch=0.91] {'loss': 0.194, 'grad_norm': 6.711526870727539, 'learning_rate': 6.954545454545455e-05, 'epoch': 0.9090909090909091}
[Step=150, Epoch=1.36] {'loss': 0.1643, 'grad_norm': 2.9699819087982178, 'learning_rate': 5.931818181818182e-05, 'epoch': 1.3636363636363638}
[Step=200, Epoch=1.82] {'loss': 0.128, 'grad_norm': 0.18381008505821228, 'learning_rate': 4.909090909090909e-05, 'epoch': 1.8181818181818183}
[Step=250, Epoch=2.27] {'loss': 0.095, 'grad_norm': 0.09163512289524078, 'learning_rate': 3.8863636363636364e-05, 'epoch': 2.2727272727272725}
[Step=300, Epoch=2.73] {'loss': 0.094, 'grad_norm': 0.0942893847823143, 'learning_rate': 2.8636363636363637e-05, 'epoch': 2.7272727272727275}
[Step=350, Epoch=3.18] {'loss': 0.064, 'grad_norm': 0.06368961930274963, 'learning_rate': 1.840909090909091e-05, 'epoch': 3.1818181818181817}
[Step=400, Epoch=3.64] {'loss': 0.056, 'grad_norm': 0.06767269968986511, 'learning_rate': 8.181818181818183e-06, 'epoch': 3.6363636363636362}
[Step=440, Epoch=4.00] {'train_runtime': 222.8998, 'train_samples_per_second': 15.666, 'train_steps_per_second': 1.974, 'total_flos': 919031286988800.0, 'train_loss': 0.13807665434750643, 'epoch': 4.0}
